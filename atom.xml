<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Monologue From a Data Geek</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-03-30T05:59:59.636Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Henry Gao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>IS/NIS-DEA Project</title>
    <link href="http://yoursite.com/2020/03/30/IS-DEA-Project/"/>
    <id>http://yoursite.com/2020/03/30/IS-DEA-Project/</id>
    <published>2020-03-30T05:51:07.000Z</published>
    <updated>2020-03-30T05:59:59.636Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;IS-NIS-DEA-Project-colleborated-with-Amazon-employee&quot;&gt;&lt;a href=&quot;#IS-NIS-DEA-Project-colleborated-with-Amazon-employee&quot; class=&quot;headerlink&quot; title=&quot;IS/NIS-DEA Project colleborated with Amazon employee&quot;&gt;&lt;/a&gt;IS/NIS-DEA Project colleborated with Amazon employee&lt;/h2&gt;&lt;p&gt;Use Tableau to analysis delivery miss root cause and apply random forest to forecast ‘obsolete’ sign of products. Source code for random forest and data processing is in my &lt;a href=&quot;https://github.com/GYHenryTT/NIS-DEA-Model&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Amazon" scheme="http://yoursite.com/tags/Amazon/"/>
    
      <category term="Random Forest" scheme="http://yoursite.com/tags/Random-Forest/"/>
    
  </entry>
  
  <entry>
    <title>N Grams Project</title>
    <link href="http://yoursite.com/2020/03/25/N-Grams-Project/"/>
    <id>http://yoursite.com/2020/03/25/N-Grams-Project/</id>
    <published>2020-03-25T04:17:48.000Z</published>
    <updated>2020-03-30T05:48:04.980Z</updated>
    
    <summary type="html">
    
      &lt;div align=&quot;center&quot;&gt;

&lt;h1 id=&quot;N-gram-Language-Models-and-Evaluation&quot;&gt;&lt;a href=&quot;#N-gram-Language-Models-and-Evaluation&quot; class=&quot;headerlink&quot; title=&quot;N-gram Language Models and Evaluation&quot;&gt;&lt;/a&gt;N-gram Language Models and Evaluation&lt;/h1&gt;&lt;/div&gt;

&lt;h2 id=&quot;Program-Instruction&quot;&gt;&lt;a href=&quot;#Program-Instruction&quot; class=&quot;headerlink&quot; title=&quot;Program Instruction&quot;&gt;&lt;/a&gt;Program Instruction&lt;/h2&gt;&lt;p&gt;Source code can be found on my &lt;a href=&quot;https://github.com/GYHenryTT/Computational-Linguistic/tree/master/PA3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;1-Bigram-model&quot;&gt;&lt;a href=&quot;#1-Bigram-model&quot; class=&quot;headerlink&quot; title=&quot;1. Bigram model&quot;&gt;&lt;/a&gt;1. Bigram model&lt;/h3&gt;&lt;p&gt;My bigram model has a different word dictionary from unigram model. I set 0 as the index of STOP word, and for the other words, index is in alphabetical order. In terms of &lt;strong&gt;generateWord(self, context)&lt;/strong&gt; function, I used &lt;strong&gt;numpy.random.choice&lt;/strong&gt; to generate next word according to the bigram conditional probabilities.&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="N-grams" scheme="http://yoursite.com/tags/N-grams/"/>
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="Computational Linguistics" scheme="http://yoursite.com/tags/Computational-Linguistics/"/>
    
  </entry>
  
  <entry>
    <title>Model Evaluation</title>
    <link href="http://yoursite.com/2020/03/06/Model-Evaluation/"/>
    <id>http://yoursite.com/2020/03/06/Model-Evaluation/</id>
    <published>2020-03-07T04:19:22.000Z</published>
    <updated>2020-03-07T04:24:24.038Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h1 id=&quot;Model-Evaluation&quot;&gt;&lt;a href=&quot;#Model-Evaluation&quot; class=&quot;headerlink&quot; title=&quot;Model Evaluation&quot;&gt;&lt;/a&gt;Model Evaluation&lt;/h1&gt;&lt;p&gt;To be
        
      
    
    </summary>
    
    
      <category term="Learning Journal" scheme="http://yoursite.com/categories/Learning-Journal/"/>
    
    
      <category term="Classifier Evaluation" scheme="http://yoursite.com/tags/Classifier-Evaluation/"/>
    
      <category term="Regression Evaluation" scheme="http://yoursite.com/tags/Regression-Evaluation/"/>
    
  </entry>
  
  <entry>
    <title>N-grams and HMM</title>
    <link href="http://yoursite.com/2020/03/06/N-grams-and-HMM/"/>
    <id>http://yoursite.com/2020/03/06/N-grams-and-HMM/</id>
    <published>2020-03-06T22:06:23.000Z</published>
    <updated>2020-03-24T20:10:34.901Z</updated>
    
    <summary type="html">
    
      &lt;div align=&quot;center&quot;&gt;

&lt;h1 id=&quot;Language-Modeling-and-Sequence-Labeling-N-grams-and-HMM&quot;&gt;&lt;a href=&quot;#Language-Modeling-and-Sequence-Labeling-N-grams-and-HMM&quot; class=&quot;headerlink&quot; title=&quot;Language Modeling and Sequence Labeling (N-grams and HMM)&quot;&gt;&lt;/a&gt;Language Modeling and Sequence Labeling (N-grams and HMM)&lt;/h1&gt;&lt;/div&gt;

&lt;h2 id=&quot;Working-Example&quot;&gt;&lt;a href=&quot;#Working-Example&quot; class=&quot;headerlink&quot; title=&quot;Working Example&quot;&gt;&lt;/a&gt;Working Example&lt;/h2&gt;&lt;h3 id=&quot;1-N-grams&quot;&gt;&lt;a href=&quot;#1-N-grams&quot; class=&quot;headerlink&quot; title=&quot;1. N-grams&quot;&gt;&lt;/a&gt;1. N-grams&lt;/h3&gt;&lt;p&gt;Given the following short sentences:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Alice admired Dorothy 
Dorothy admired every dwarf 
Dorothy cheered 
every dwarf cheered&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
    
    
      <category term="N-grams" scheme="http://yoursite.com/tags/N-grams/"/>
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="Computational Linguistics" scheme="http://yoursite.com/tags/Computational-Linguistics/"/>
    
      <category term="Hidden Markov Models" scheme="http://yoursite.com/tags/Hidden-Markov-Models/"/>
    
  </entry>
  
  <entry>
    <title>Naive Bayes Classifier</title>
    <link href="http://yoursite.com/2020/03/01/Naive-Bayes-Classifier/"/>
    <id>http://yoursite.com/2020/03/01/Naive-Bayes-Classifier/</id>
    <published>2020-03-01T22:06:45.000Z</published>
    <updated>2020-03-07T06:04:48.336Z</updated>
    
    <summary type="html">
    
      &lt;div align=&quot;center&quot;&gt;

&lt;h1 id=&quot;Naive-Bayes-Classifier-and-Evaluation&quot;&gt;&lt;a href=&quot;#Naive-Bayes-Classifier-and-Evaluation&quot; class=&quot;headerlink&quot; title=&quot;Naive Bayes Classifier and Evaluation&quot;&gt;&lt;/a&gt;Naive Bayes Classifier and Evaluation&lt;/h1&gt;&lt;/div&gt;

&lt;h2 id=&quot;Program-Instruction&quot;&gt;&lt;a href=&quot;#Program-Instruction&quot; class=&quot;headerlink&quot; title=&quot;Program Instruction&quot;&gt;&lt;/a&gt;Program Instruction&lt;/h2&gt;&lt;p&gt;The source code has been posted in my &lt;a href=&quot;https://github.com/GYHenryTT/Computational-Linguistic/tree/master/PA2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Basic Naive Bayes function: $$P(C|W)=\frac{P(W|C)P(C)}{P(W)}$$&lt;br&gt;$$P(C|W) \propto P(W|C)P(C),$$&lt;/p&gt;
&lt;p&gt;where $P(W|C)$ is called as likelihood and  $P(C)$ as prior.&lt;/p&gt;
&lt;h3 id=&quot;1-Training-Function&quot;&gt;&lt;a href=&quot;#1-Training-Function&quot; class=&quot;headerlink&quot; title=&quot;1. Training Function&quot;&gt;&lt;/a&gt;1. Training Function&lt;/h3&gt;&lt;p&gt;To collect the word counts, we need to first split the text in the training set. In this case, I used regular expression &lt;strong&gt;‘[^A-Za-z\‘]+’&lt;/strong&gt; as the seperator. Specifically, it will discard all non-letters except for single quote because some word with quote may have different meanings such as “I’m”, “That’s”, etc.&lt;/p&gt;
&lt;p&gt;Then, the class initialization was changed. I used set to collect all the features, and use variable &lt;em&gt;class_count&lt;/em&gt; to collect class numbers. Inside the train function, it can visit every seperate word and generate word counts based on the document’s class. Accordingly, it will caculate the priors and likelihoods.&lt;/p&gt;
    
    </summary>
    
    
      <category term="Project" scheme="http://yoursite.com/categories/Project/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="Computational Linguistics" scheme="http://yoursite.com/tags/Computational-Linguistics/"/>
    
      <category term="Naive Bayes" scheme="http://yoursite.com/tags/Naive-Bayes/"/>
    
  </entry>
  
  <entry>
    <title>Naive Bayes and Logistic Regression</title>
    <link href="http://yoursite.com/2020/02/20/Naive-Bayes-and-Logistic-Regression/"/>
    <id>http://yoursite.com/2020/02/20/Naive-Bayes-and-Logistic-Regression/</id>
    <published>2020-02-20T18:14:09.000Z</published>
    <updated>2020-03-07T05:28:49.674Z</updated>
    
    <summary type="html">
    
      &lt;div align=&quot;center&quot;&gt;

&lt;h1 id=&quot;Naive-Bayes-and-Logistic-Regression-in-Text-Classification&quot;&gt;&lt;a href=&quot;#Naive-Bayes-and-Logistic-Regression-in-Text-Classification&quot; class=&quot;headerlink&quot; title=&quot;Naive Bayes and Logistic Regression in Text Classification&quot;&gt;&lt;/a&gt;Naive Bayes and Logistic Regression in Text Classification&lt;/h1&gt;&lt;/div&gt;

&lt;h2 id=&quot;1-Generative-and-Discriminative-Classifiers&quot;&gt;&lt;a href=&quot;#1-Generative-and-Discriminative-Classifiers&quot; class=&quot;headerlink&quot; title=&quot;1. Generative and Discriminative Classifiers&quot;&gt;&lt;/a&gt;1. Generative and Discriminative Classifiers&lt;/h2&gt;&lt;p&gt;The most important difference between naive Bayes and logistic regression is that logistic regression is a discriminative classifier while naive Bayes is a generative classifier. These are two very different frameworks for how to build a machine learning model.&lt;/p&gt;
    
    </summary>
    
    
      <category term="Learning Journal" scheme="http://yoursite.com/categories/Learning-Journal/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="Computational Linguistics" scheme="http://yoursite.com/tags/Computational-Linguistics/"/>
    
      <category term="Naive Bayes" scheme="http://yoursite.com/tags/Naive-Bayes/"/>
    
      <category term="Logistic Regression" scheme="http://yoursite.com/tags/Logistic-Regression/"/>
    
      <category term="Gradient Descent" scheme="http://yoursite.com/tags/Gradient-Descent/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning Projects</title>
    <link href="http://yoursite.com/2018/01/11/Deep-Learning-Projects/"/>
    <id>http://yoursite.com/2018/01/11/Deep-Learning-Projects/</id>
    <published>2018-01-12T04:16:28.000Z</published>
    <updated>2020-03-12T04:30:45.438Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Source codes have been uploaded to my &lt;a href=&quot;https://github.com/GYHenryTT/Deep-Learning-Projects&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;github&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-Convolution-Neural-Networks-CNN&quot;&gt;&lt;a href=&quot;#1-Convolution-Neural-Networks-CNN&quot; class=&quot;headerlink&quot; title=&quot;1. Convolution Neural Networks (CNN)&quot;&gt;&lt;/a&gt;1. Convolution Neural Networks (CNN)&lt;/h2&gt;
    
    </summary>
    
    
      <category term="Project" scheme="http://yoursite.com/categories/Project/"/>
    
    
      <category term="CNN" scheme="http://yoursite.com/tags/CNN/"/>
    
      <category term="RNN" scheme="http://yoursite.com/tags/RNN/"/>
    
      <category term="RBM" scheme="http://yoursite.com/tags/RBM/"/>
    
      <category term="Reinforcement Learning" scheme="http://yoursite.com/tags/Reinforcement-Learning/"/>
    
  </entry>
  
</feed>
