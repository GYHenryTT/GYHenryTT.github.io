<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Monologue From a Data Geek</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-03-07T04:24:24.038Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Henry Gao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Model Evaluation</title>
    <link href="http://yoursite.com/2020/03/06/Model-Evaluation/"/>
    <id>http://yoursite.com/2020/03/06/Model-Evaluation/</id>
    <published>2020-03-07T04:19:22.000Z</published>
    <updated>2020-03-07T04:24:24.038Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h1 id=&quot;Model-Evaluation&quot;&gt;&lt;a href=&quot;#Model-Evaluation&quot; class=&quot;headerlink&quot; title=&quot;Model Evaluation&quot;&gt;&lt;/a&gt;Model Evaluation&lt;/h1&gt;&lt;p&gt;To be
        
      
    
    </summary>
    
    
      <category term="Learning Journal" scheme="http://yoursite.com/categories/Learning-Journal/"/>
    
    
      <category term="Classifier Evaluation" scheme="http://yoursite.com/tags/Classifier-Evaluation/"/>
    
      <category term="Regression Evaluation" scheme="http://yoursite.com/tags/Regression-Evaluation/"/>
    
  </entry>
  
  <entry>
    <title>N-grams and HMM</title>
    <link href="http://yoursite.com/2020/03/06/N-grams-and-HMM/"/>
    <id>http://yoursite.com/2020/03/06/N-grams-and-HMM/</id>
    <published>2020-03-06T22:06:23.000Z</published>
    <updated>2020-03-07T01:48:59.662Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;div align=&quot;center&quot;&gt;

&lt;h1 id=&quot;Language-Modeling-and-Sequence-Labeling-N-grams-and-HMM&quot;&gt;&lt;a
        
      
    
    </summary>
    
    
    
      <category term="N-grams" scheme="http://yoursite.com/tags/N-grams/"/>
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="Computational Linguistics" scheme="http://yoursite.com/tags/Computational-Linguistics/"/>
    
      <category term="Hidden Markov Models" scheme="http://yoursite.com/tags/Hidden-Markov-Models/"/>
    
  </entry>
  
  <entry>
    <title>Naive Bayes Classifier</title>
    <link href="http://yoursite.com/2020/03/01/Naive-Bayes-Classifier/"/>
    <id>http://yoursite.com/2020/03/01/Naive-Bayes-Classifier/</id>
    <published>2020-03-01T22:06:45.000Z</published>
    <updated>2020-03-07T04:24:36.340Z</updated>
    
    <summary type="html">
    
      &lt;div align=&quot;center&quot;&gt;

&lt;h1 id=&quot;Naive-Bayes-Classifier-and-Evaluation&quot;&gt;&lt;a href=&quot;#Naive-Bayes-Classifier-and-Evaluation&quot; class=&quot;headerlink&quot; title=&quot;Naive Bayes Classifier and Evaluation&quot;&gt;&lt;/a&gt;Naive Bayes Classifier and Evaluation&lt;/h1&gt;&lt;/div&gt;

&lt;h2 id=&quot;Program-Instruction&quot;&gt;&lt;a href=&quot;#Program-Instruction&quot; class=&quot;headerlink&quot; title=&quot;Program Instruction&quot;&gt;&lt;/a&gt;Program Instruction&lt;/h2&gt;&lt;p&gt;The source code has been posted in my &lt;a href=&quot;https://github.com/GYHenryTT/Computational-Linguistic/tree/master/PA2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Basic Naive Bayes function: $$P(C|w)=\frac{P(W|C)P(C)}{P(W)}$$&lt;br&gt;$$P(C|W) \propto P(W|C)P(C),$$&lt;/p&gt;
&lt;p&gt;where $P(W|C)$ is called as likelihood and  $P(C)$ as prior.&lt;/p&gt;
&lt;h3 id=&quot;1-Training-Function&quot;&gt;&lt;a href=&quot;#1-Training-Function&quot; class=&quot;headerlink&quot; title=&quot;1. Training Function&quot;&gt;&lt;/a&gt;1. Training Function&lt;/h3&gt;&lt;p&gt;To collect the word counts, we need to first split the text in the training set. In this case, I used regular expression &lt;strong&gt;‘[^A-Za-z\‘]+’&lt;/strong&gt; as the seperator. Specifically, it will discard all non-letters except for single quote because some word with quote may have different meanings such as “I’m”, “That’s”, etc.&lt;/p&gt;
&lt;p&gt;Then, the class initialization was changed. I used set to collect all the features, and use variable &lt;em&gt;class_count&lt;/em&gt; to collect class numbers. Inside the train function, it can visit every seperate word and generate word counts based on the document’s class. Accordingly, it will caculate the priors and likelihoods.&lt;/p&gt;
    
    </summary>
    
    
      <category term="Project" scheme="http://yoursite.com/categories/Project/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="Computational Linguistics" scheme="http://yoursite.com/tags/Computational-Linguistics/"/>
    
      <category term="Naive Bayes" scheme="http://yoursite.com/tags/Naive-Bayes/"/>
    
  </entry>
  
  <entry>
    <title>Naive Bayes and Logistic Regression</title>
    <link href="http://yoursite.com/2020/02/20/Naive-Bayes-and-Logistic-Regression/"/>
    <id>http://yoursite.com/2020/02/20/Naive-Bayes-and-Logistic-Regression/</id>
    <published>2020-02-20T18:14:09.000Z</published>
    <updated>2020-03-07T04:27:34.022Z</updated>
    
    <summary type="html">
    
      &lt;div align=&quot;center&quot;&gt;

&lt;h1 id=&quot;Naive-Bayes-and-Logistic-Regression-in-Text-Classification&quot;&gt;&lt;a href=&quot;#Naive-Bayes-and-Logistic-Regression-in-Text-Classification&quot; class=&quot;headerlink&quot; title=&quot;Naive Bayes and Logistic Regression in Text Classification&quot;&gt;&lt;/a&gt;Naive Bayes and Logistic Regression in Text Classification&lt;/h1&gt;&lt;/div&gt;

&lt;h2 id=&quot;1-Generative-and-Discriminative-Classifiers&quot;&gt;&lt;a href=&quot;#1-Generative-and-Discriminative-Classifiers&quot; class=&quot;headerlink&quot; title=&quot;1. Generative and Discriminative Classifiers&quot;&gt;&lt;/a&gt;1. Generative and Discriminative Classifiers&lt;/h2&gt;&lt;p&gt;The most important difference between naive Bayes and logistic regression is that logistic regression is a discriminative classifier while naive Bayes is a generative classifier. These are two very different frameworks for how to build a machine learning model.&lt;/p&gt;
    
    </summary>
    
    
      <category term="Learning Journal" scheme="http://yoursite.com/categories/Learning-Journal/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="Computational Linguistics" scheme="http://yoursite.com/tags/Computational-Linguistics/"/>
    
      <category term="Naive Bayes" scheme="http://yoursite.com/tags/Naive-Bayes/"/>
    
      <category term="Logistic Regression" scheme="http://yoursite.com/tags/Logistic-Regression/"/>
    
      <category term="Gradient Descent" scheme="http://yoursite.com/tags/Gradient-Descent/"/>
    
  </entry>
  
</feed>
